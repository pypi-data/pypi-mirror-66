dataset_config:
  visual_entailment:
      data_root_dir: ../data
      image_depth_first: false
      fast_read: false
      image_features:
        train:
        - datasets/visual_entailment/features/lmdbs/flickr30k.lmdb
        val:
        - datasets/visual_entailment/features/lmdbs/flickr30k.lmdb
        test:
        - datasets/visual_entailment/features/lmdbs/flickr30k.lmdb
      imdb_files:
        train:
        - datasets/visual_entailment/imdbs/snli_ve_train.jsonl
        val:
        - datasets/visual_entailment/imdbs/snli_ve_dev.jsonl
        test:
        - datasets/visual_entailment/imdbs/snli_ve_test.jsonl
      features_max_len: 100
      processors:
        text_processor:
          type: vocab
          params:
            max_length: 14
            vocab:
              type: intersected
              embedding_name: glove.6B.300d
              vocab_file: vocabs/vocabulary_100k.txt
            preprocessor:
              type: simple_sentence
              params: {}
        bbox_processor:
          type: bbox
          params:
            max_length: 50
      return_info: false
      # Return OCR information
      use_ocr: false
      # Return spatial information of OCR tokens if present
      use_ocr_info: false
training:
    monitored_metric: visual_entailment/accuracy
    metric_minimize: false

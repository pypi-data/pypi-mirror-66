{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = !git rev-parse --show-toplevel\n",
    "import os; os.chdir(root_dir[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = 'http://www.atlasbrasil.org.br'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADERS = ''' \n",
    "    -H 'Connection: keep-alive'\n",
    "    -H 'Cache-Control: max-age=0'\n",
    "    -H 'Upgrade-Insecure-Requests: 1'\n",
    "    -H 'User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36'\n",
    "    -H 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3'\n",
    "    -H 'Referer: http://www.atlasbrasil.org.br/2013/pt/consulta/'\n",
    "    -H 'Accept-Language: en-US,en;q=0.9,pt-BR;q=0.8,pt;q=0.7'\n",
    "'''.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl '{BASE_URL}/2013/pt/download/' {HEADERS} --insecure > /tmp/a.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs4.BeautifulSoup(open('/tmp/a.html').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = soup.find('head').find('base').attrs['href']\n",
    "BASE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloads = soup.find_all(class_='blue_button')\n",
    "links = [b.parent.attrs['href'] for b in downloads]\n",
    "assert  links[0] == 'data/rawData/Indicadores Atlas - RADAR IDHM.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "for l in links[:]:\n",
    "    url = BASE_URL + BASE_PATH + urllib.parse.quote(l)\n",
    "    print(url)\n",
    "    file = l.split('/')[-1]\n",
    "    !cd data/raw/; curl \"{url}\" {HEADERS} --insecure -o '{file}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !head data/raw/Indicadores\\ Atlas\\ -\\ RADAR\\ IDHM.xlsx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = !ls -1 data/raw/*.zip | wc --lines\n",
    "size = !du -s data/raw/\n",
    "\n",
    "assert int(size[0].split('\\t')[0]) > 10000, size\n",
    "assert lines[0] == '24', lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzippin all this crap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf data/preprocessed\n",
    "mkdir -p data/preprocessed\n",
    "mkdir -p data/preprocessed/others\n",
    "cp data/raw/* data/preprocessed/\n",
    "shopt -s extglob\n",
    "cd data/preprocessed/ && mv !(dados_*.zip|others) others "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -e\n",
    "cd data/preprocessed/\n",
    "unp *.zip > /dev/null 2>&1\n",
    "find . -mindepth 2 -type f -exec mv -t . '{}' +\n",
    "yes | unp *.rar > /dev/null 2>&1\n",
    "find . -mindepth 2 -type f -exec mv -t . '{}' +\n",
    "rm *.zip *.rar\n",
    "find . -mindepth 1 -type d -exec rmdir '{}' +\n",
    "echo done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -e\n",
    "cd data/preprocessed/\n",
    "mkdir udh; mkdir regional; mkdir regiao_metro;\n",
    "mv *UDH* udh/\n",
    "mv *Regional* regional/\n",
    "mv *REGIO* regional/\n",
    "mv *RM* regiao_metro/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "exit 0\n",
    "## Delete all non UDH files\n",
    "set -e\n",
    "cd data/preprocessed/udh/\n",
    "mkdir die; mkdir save;\n",
    "mv *UDH* save/\n",
    "mv * die/ > /dev/null 2>&1 || true\n",
    "mv die/save .\n",
    "rm -r die\n",
    "mv save/* .\n",
    "rmdir save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = !ls -1 data/preprocessed/udh/*.shp | wc --lines\n",
    "size = !du -s data/raw/\n",
    "\n",
    "assert int(size[0].split('\\t')[0]) > 10000, size\n",
    "assert lines[0] == '24', lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Excels to parquets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "excels = glob.glob('data/preprocessed/udh/*.xlsx')\n",
    "excels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excels.remove('data/preprocessed/udh/agrupamento_UDHs_para_calculo_no_IBGE_2000_2010.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing, glob, pandas as pd\n",
    "import pyarrow.lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = multiprocessing.Pool()\n",
    "def convert_to_parquet(path):\n",
    "    print(f'converting {path}')\n",
    "    dfs = pd.read_excel(path, sheet_name=None)\n",
    "    for sheet_name, df in dfs.items():\n",
    "        try:\n",
    "            if df.empty: continue\n",
    "            df.to_parquet(path.replace('.xlsx', '__' + sheet_name + '.parquet'), index=False)\n",
    "        except (Exception, pyarrow.lib.ArrowTypeError) as e:\n",
    "            print('error in:')\n",
    "            print((path, sheet_name, e))\n",
    "res = list(pool.map(convert_to_parquet, excels))\n",
    "del pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -sh data/preprocessed/udh/*parquet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

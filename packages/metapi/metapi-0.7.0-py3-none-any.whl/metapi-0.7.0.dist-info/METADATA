Metadata-Version: 2.1
Name: metapi
Version: 0.7.0
Summary: a pipeline to construct a genome catalogue from metagenomics data
Home-page: https://github.com/ohmeta/metapi
Author: Jie Zhu
Author-email: zhujie@genomics.cn
License: GPLv3
Platform: UNKNOWN
Classifier: Development Status :: 2 - Pre-Alpha
Classifier: Environment :: Console
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: GNU General Public License v3 (GPLv3)
Classifier: Natural Language :: English
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3.5
Classifier: Programming Language :: Python :: 3.6
Classifier: Programming Language :: Python :: 3.7
Classifier: Topic :: Scientific/Engineering :: Bio-Informatics
Requires-Python: >=3.5
Description-Content-Type: text/markdown
Requires-Dist: pandas
Requires-Dist: ruamel.yaml

#+TITLE: metapi

* Install
#+BEGIN_SRC bash
conda install metapi
#+END_SRC

* Run
** help
#+BEGIN_SRC bash
$ metapi --help

.___  ___.  _______ .___________.    ___      .______    __
|   \/   | |   ____||           |   /   \     |   _  \  |  |
|  \  /  | |  |__   `---|  |----`  /  ^  \    |  |_)  | |  |
|  |\/|  | |   __|      |  |      /  /_\  \   |   ___/  |  |
|  |  |  | |  |____     |  |     /  _____  \  |  |      |  |
|__|  |__| |_______|    |__|    /__/     \__\ | _|      |__|

Omics for All, Open Source for All

A pipeline to construct a genome catalogue from metagenomics data

optional arguments:
-h, --help     show this help message and exit
-v, --version  print software version and exit

available subcommands:

init         init project
denovo_wf    denovo_wf pipeline
#+END_SRC
** init
#+BEGIN_SRC bash
$ metapi init --help

usage: metapi init [-h] [-d WORKDIR] [-s SAMPLES]
                   [-b {simulate,trimmingrmhost,assembly}]

arguments:
  -h, --help            show this help message and exit
  -d WORKDIR, --workdir WORKDIR
                        project workdir
  -s SAMPLES, --samples SAMPLES
                        samples list, tsv format required if begin from
                        trimming, rmhost, or assembly: if it is fastq: the
                        header is [id, fq1, fq2], else it is sra: the header
                        is [id, sra] else begin from simulate: the header is
                        [id, genome, abundance, reads_num, model]
-b {simulate,trimming,rmhost,assembly}, --begin {simulate,trimming,rmhost,assembly}
                        pipeline starting point
#+END_SRC

** denovo_wf
#+BEGIN_SRC bash
$ metapi denovo_wf --help

usage: metapi denovo_wf [-h] [-d WORKDIR] [--cores CORES] [--jobs JOBS]
                        [--list] [--run] [--debug] [--dry_run] [--qsub]
                        [--wait WAIT] [--snake [SNAKEMAKEARGS]]
                        [TASK]

positional arguments:
  TASK                  pipeline end point. Allowed values are simulate_all,
                        prepare_reads_all, raw_fastqc_all, rmhost_bwa_all,
                        rmhost_bowtie2_all, rmhost_all, assebmly_megahit_all,
                        assembly_idba_ud_all, assembly_metaspades_all,
                        assembly_spades_all, assembly_metaquast_all,
                        assembly_report_all, assembly_all,
                        alignment_base_depth_all, alignment_all,
                        binning_metabat2_all, binning_maxbin2_all,
                        binning_all, predcit_scafitgs_gene_all,
                        predict_bins_gene_all, predcit_all, checkm_link_bins,
                        checkm_all, dereplicate_drep_all, dereplicate_all,
                        classify_short_reads_kraken2_all,
                        classify_hmq_bins_gtdbtk_all, classify_all,
                        profiling_metaphlan2_all, profiling_jgi_all,
                        profiling_humann2_all, profiling_all,
                        upload_sequencing_all, upload_assembly_all,
                        upload_all, all

arguments:
  -h, --help            show this help message and exit
  -d WORKDIR, --workdir WORKDIR
                        project workdir, default: ./
  --cores CORES         CPU cores
  --jobs JOBS           qsub job numbers
  --list                list pipeline rules
  --run                 run pipeline
  --debug               debug pipeline
  --dry_run             dry run pipeline
  --qsub                qsub pipeline
  --wait WAIT           wait given seconds
  --snake [SNAKEMAKEARGS]
                        other snakemake command options, if want --touch, just
                        --snake touch
#+END_SRC

** input requirements
Please supply samples.tsv format like below:
| id | fq1           | fq2           |
|----+---------------+---------------|
| s1 | s1.1.fq.gz    | s1.2.fq.gz    |
| s2 | s2.1.fq.gz    | s2.2.fq.gz    |
| s2 | s21.1.fq.gz   | s21.2.fq.g    |
| s3 | hello.1.fq.gz | hello.2.fq.gz |
The header must be: id fq1 fq2.
If id is same, the fq1 and fq2 belong to one sample, and will be merged to
process.

* License
- Omics for all, Open Source for all.
- GPLv3+



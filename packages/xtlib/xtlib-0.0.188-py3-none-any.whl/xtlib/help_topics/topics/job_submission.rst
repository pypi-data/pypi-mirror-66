.. _job_submission:

=======================================
Job Submission and Running
=======================================

This page details the steps involved when you use the **run** command to submit a job to XT:
    - Job Submission
    - Job Running

The submission of a job can be broken down into 4 stages:
    - Hyperparameter Search processing
    - Building the Setup Script
    - Building the Code Snapshot
    - Job Submission

----------------------------------
Hyperparameter Search Processing
----------------------------------

Hyperparameter search processing consists of the following steps:
    - gather hyperparameter search specs from script command line 
    - gather hyperparameter search specs from specified `--hp-config` file
    - determining search style (single, repeat, multi, static, dynamic)
    - generating static hyperparam_search commands

----------------------------------
Building the Setup Script
----------------------------------

The setup script is reponsible for preparing the compute node to run
the XT controller, or the user's ML app (in the case of a direct run).

The script is built by adding commands for various needed tasks, depending on the user's config settings 
and the associated backend service.

Comands can be grouped into these functions:
    - setup specifications (activate cmd, conda packages, python packages)
    - data/model storage mount or file downloads
    - environment variable settings
    - launch the XT controller or user app

----------------------------------
Building the Code Snapshot
----------------------------------

Building the code snapshot consists of the following steps:
    - create a temporary directory on the local machine
    - process each entry in the **code-dirs** property of the XT config file:
        - an entry has one of the following string formats:
        - source   (copies the **source** files (relative to the current directory) to the snapshot root directory, using the basename of the **source** directory, if any)
        - source::dest (copies the specified **source** files (relative to the current directory) to the snapshot root directory named **dest**)

    - 1-3 other files generated by XT during the job submission are also included in the code snapshot
        
----------------------------------
Job Submission
----------------------------------

Job submission consists of the following steps:
    - create a new XT job
    - a "capture_before" event is logged for the job
    - a **job_secret** is generated for the job (to later authenticate client requests to the XT controller)
    - creates an XT Run for each node
    - a "created" event is logged for each run
    - upload code snapshot to the job storage
    - build service configuration params
        - user and XT environment variables
    - submit job to backend service
    - service-id data for the job is written to the job properties (in MongoDB)
    - a "queued" event is logged for each run

--------------------------------
Job Running
--------------------------------

The running of a job consists of:

    - Backend service processing
        - some services may auto-build docker images for your job (Azure ML)
        - Jobs are queued for running
        - Compute nodes are allocated by the backend service

    - Node preparation:
            - once a node has been allocated for the job, the service prepares the run environment (including GPUs, port openings, etc.)

    - Node execution:
            - XT setup script runs (activate cmd, conda, pip, data/model mount/download)
            - XT Controller starts running (for non-direct runs)
            - user's script starts running (for direct runs)

    - Node wrapup:
            - service may upload specified output files 

.. seealso:: 

    - :ref:`Hyperparameter Search <hyperparameter_search>`
    - :ref:`How XT Works <how_xt_works>`
    - :ref:`XT Controller <xt_controller>`
